
import re


#Open file parser-output.txt which is generated by running isc-parser
#store the contents into parser_output_lines 
#Enter the parser input file
parser_file_input="txt_files/parser-output.txt"
prune_file_input="txt_files/prune-output.txt"
wx_file_input="txt_files/wx.txt"
ner_file_input="txt_files/ner_output"
#concept_dictionary_input="H_concept-to-mrs-rels.dat"
#Open the parser file,and store its contents into a 2d-list
parser_output_list=[]
with open(parser_file_input,"r",encoding="UTF-8") as pf:
    parser_output_lines=pf.readlines()
parser_output_lines.pop()
#we append the lines into a list thereby it is 2d list parser_output_list
for line in parser_output_lines:
    parser_output_list.append(line.split())

#Open pruner file and store all its words into a 2d list
prune_output_list=[]
f=open(prune_file_input,"r",encoding="UTF-8")
for line in f:
    prune_output_list.append(line.strip())
f.close()
#print("pol:",prune_output_list)

#open wx file and append it into a list
wx_output_list=[]
with open(wx_file_input,"r",encoding="UTF-8") as pf:
    wx_list=pf.readlines()
    wx_output_list=wx_list[0].split()

#print(wx_output_list)
#---------------------------------------------------------------

#--------------------------------------------------------------------
#---------------------------------------------------------------------
#root word dictionary
root_word_dict_reverse={} #key==wx_word and value is root_word from prune output
root_word_dict={} #key=root_word and value is wx_word
for sent in prune_output_list:
    split_sent=sent.split(",")
    wx_word=split_sent[1]
    root_word=split_sent[2]
    root_word_dict_reverse[wx_word]=root_word
    root_word_dict[root_word]=wx_word
#print(root_word_dict_reverse.get("PlOYpI"))
#print(root_word_dict_reverse["oYPisa"])
#print("rw",root_word_dict)
#print("rw_dict_rev:",root_word_dict_reverse)
#----------------------------------------------------------------

#----------------------------------------------------------------------



#creating a suffix dictionary where key is word and value is suffix a.k.a 8th vector
suffix_dictionary={}
word=str()
for sent in prune_output_list:
    split_sent=sent.split(",")
    wx_word=split_sent[1]
    #print(split_sent)
    suffix=split_sent[6]
    suffix_dictionary[wx_word]=suffix

    
print("sd",suffix_dictionary)
    #print(type(word))
#---------------------------------------------------------------------
#Creating a dictionary for wx_words and their indexes
wx_words_dictionary={} #wx_words are value and keys are indexes.
index=1
for words in wx_output_list:
    wx_words_dictionary[index]=words
    index+=1
temp_wx_words_dict=wx_words_dictionary#temporary for loop usage
#print("wx_orig:",wx_words_dictionary)
#------------------------------------------------------------------------
#creating a dictionary for parser_output_list
parser_output_dict={}
index=1
for par_value in parser_output_list:
    parser_output_dict[index]=par_value
    index+=1
#print(parser_output_dict)
#--------------------------------------------------------------------
#Creating a reverse dictionary for wx_words and their indexes
wx_words_dictionary_new={} #wx_words are key and values are indexes.
index=1
for words in wx_output_list:
    wx_words_dictionary_new[words]=index
    index+=1
temp_wx_words_dict=wx_words_dictionary_new#temporary for loop usage
#print("wx_words:",wx_words_dictionary_new)
#---------------------------------------------------------------------
#Open NER file and append its output into a list
# NER_dict={}
# inx=0
# y=open(ner_file_input,"r")
# for line in y:
#     inx+=1
#     token=line.strip()
#     if token.split("\t")[1]!="O":
#         wx_word=wx_words_dictionary[inx]
#         #print(wx_word)
#         NER_dict[wx_word]=token.split("\t")[1]
#y.close()
#print("ner_dict:",NER_dict)
#----------------------------------------------------------------------
concept_list=[]
used_root_word=set()
updated_root_word={}
info_list_final=[] #list containing important values from parser output file
for line in parser_output_list:
    info_list_temp=[]
    word_index=int(line[0])
    pos_tag=line[3]
    class_index=line[6]
    word_info=line[7]
    info_list_temp.append(word_index)
    info_list_temp.append(pos_tag)
    info_list_temp.append(class_index)
    info_list_temp.append(word_info)
    info_list_final.append(info_list_temp)
#for line in info_list_final:
#    print(line)
#--------------------------------------------------------------------
#Creating a TAM dictionary
#open the file and read its data into a list[str]
#split the data by tab and append these lists into a 2-d list TAM_dictionary_list
#remove its first element because 1st and 2nd element is repeated
f=open("TAM-num-per-details.tsv.wx","r")
TAM_dictionary_list=[]
data=f.readlines()
for line in data:
    line=line.split("\t")
    line=[s.strip() for s in line]
    TAM_dictionary_list.append(line)

for line in TAM_dictionary_list:
    line.pop(0)

#for line in TAM_dictionary_list:
    #print(line)
#---------------------------------------------------------------------   
def search_concept(search_word):
    key=0
    for word in concept_dictionary_list:
        if word==search_word:
            key=1
            break
    if key==0:
        print("Warning:{} not found in dictionary.".format(search_word))    
#----------------------------------------------------------------
#To print 1st row of USR which is the Original Sentence
def get_row1():
    row1="#"
    #orig_sent_copy=run_generate_usr.orig_sent_copy
    '''for p_list in parser_output_list:
        row1=row1+" "+p_list[1]
    row1=row1.replace("|","ред")'''
    file_temp=open("bh-2","r",encoding="UTF-8")
    sent_temp=file_temp.readline()
    #print("sent_temp",sent_temp)
    file_temp.close()
    row1=row1+""+sent_temp
    row1=row1.strip()
    #print("row1:",row1)
    return row1

#To generate groups,"Not clear about it's output.please refer"
group_list=[]
index=len(parser_output_list)
for val in range(index):
    if val==index-1 or parser_output_list[val][7]=="pof" or parser_output_list[val][7]=="pof__cn":
        group_list.append("0")
        #print(parser_output_list[val][1])
    elif parser_output_list[val][7]=="lwg__psp":
        group_list.append("-1")
        #print(parser_output_list[val][1])
    else:
        group_list.append("1")
        #print(parser_output_list[val][1])
 
#-----------------------------------------------------------------------
#Row 2 of USR Which is Concept 
#for every element in wx_output_list,check its POS TAG
#the third column in parser_output_list[][3] is POS TAG,index from 0
already_visited={} #it is currently being used for VAUX and class words which have to be ignored while checking
VM_already_visited={} #To check if VM is already updated or not.Used only for verb groups.Key is wx_word and value is updated verbgroup

def for_VM_no__1(row_2):
    for word in range(len(row_2)):
        if "+" in row_2[word]:
            ini_part=row_2[word].split("+",1)[0].strip("_1")
            
            final_part=row_2[word].split("+",1)[1]
            #print("finalpart:",final_part)
            row_2[word]=ini_part+"+"+final_part
    return row_2

def get_8th_vector(word):
    vector_8th=suffix_dictionary[word]
    return vector_8th
        
def get_root_word(word):#updated
    
    root_word=root_word_dict_reverse[word]
    
    return root_word
    
def for_handling_nnc_tag_or_pof(word,class_index):
    root_word=get_root_word(word)
    class_word=wx_words_dictionary[class_index]
    already_visited[class_word]=1
    if class_word in VM_already_visited:
        root_word_class=VM_already_visited[class_word]
        concept_list.remove(root_word_class)
    else:
        root_word_class=get_root_word(class_word)
    if root_word_class in used_root_word:
        root_word_class=updated_root_word[root_word_class]
        concept_list.remove(updated_root_word[root_word_class])
        #updated_root_word[root_word_class]=root_word+"+"+root_word_class
        #print("updated root word dict:",updated_root_word[root_word_class]) 
        
    else:
        used_root_word.add(root_word_class)
        updated_root_word[root_word_class]=root_word+"+"+root_word_class
    final_word=root_word+"+"+root_word_class+"_1"
    VM_already_visited[class_word]=final_word
    return final_word
#---------------------------------------------------------------------
#Step 1:Take the second row and identfify TAMs present in them.
def identify_vb(concept_list):
    tam_list_row2=[]
    for concept in concept_list:
        if "-" in concept:
            tam_list_row2.append(concept)
    return tam_list_row2

def word_search_from_end(search_word):
    
    if "_1" in search_word:
        search_word=search_word.strip("_1")
        search_word=root_word_dict[search_word]
    #else:
     #   search_word=root_word_dict[search_word]
    #print("search_word:",search_word)
    match_key_list=[]
    matched_tams={}
    real_tam_search=search_word.strip()
    for line in TAM_dictionary_list:
        
        for value in line:
            #print(value)
            if real_tam_search.endswith(value) and  value!="" :
                #print("val:",value)
                key=value
                line0_length=len(line[0])
                if key not in matched_tams.keys():
                    matched_tams[value]=line[0]
                else:
                    if line0_length > len(matched_tams[value]):
                        matched_tams[value]=line[0]
    longest_key=int(0)
    longest_key_value=int(0)
    key_tam=None
    for key in matched_tams:
        key_temp_length=len(key)
        if key_temp_length>longest_key:
            longest_key_value=key
            longest_key=key_temp_length
    try:
        if longest_key_value !=0:
            key_tam=matched_tams[longest_key_value]
    
        
        print("kt",key_tam)
    #key_tam is the value of longest matched TAM from TAM dictionary.
        return key_tam
    except Exception as e:
        print(e)
    
   
    
 


def search_tam_row2(concept_list):
    ranjak_list= ["cala", "dAla", "cuka", "xe", "le", "bETa", "uTa", "jA", "padZa", "A"]
    tam_list_row2=identify_vb(concept_list)
    # print("This is our vb:",tam_list_row2)
     
    for concept_with_hyphen in tam_list_row2:
        # print("The verb group to be replaced:",concept_with_hyphen)
        #concept_with_hyphen is the word in concept list that we have to replace
        if concept_with_hyphen.split("-")[1]=="":
            
            real_tam_temp="0"
        else:
            real_tam_temp=concept_with_hyphen.split("-")[1]
        # print(real_tam_temp)
        if real_tam_temp=="0":
            root_concept=concept_with_hyphen.split("-")[0]
            # print("rc:",root_concept)
            search_word=root_concept.strip("_1")
            if "+" in root_concept:
                search_word=root_concept.split("+")[1]
            if "_1" in search_word:
                search_word=search_word.strip("_1")
            search_word=root_word_dict[search_word]
            #print("sw in row2:",search_word)
            
            key_tam=word_search_from_end(search_word)
            #print("key_tam value in search_tam_row2:",key_tam)
            if key_tam !=None:
                final_concept=root_concept+"-"+key_tam
            else:
                final_concept=root_concept
            #print(final_concept)
        else:
            #Word after hyphen in verb group
            root_concept=concept_with_hyphen.split("-")[0] 
            #Word before hyphen in verb group
            # print("root_concept:",root_concept)
            root_concept=root_concept.strip("_1")
            if "+" in root_concept:
                root_concept=root_concept.split("+")[1]
            if "_1" in root_concept:
                root_concept=root_concept.strip("_1")
            wx_word_for_root_concept=root_word_dict[root_concept]
            #this is the original word for root_concept
            # print(wx_word_for_root_concept)
            #real_tam_temp=real_tam_temp.strip("_")
            for char in real_tam_temp:
                if char=="_":
                    real_tam_temp=real_tam_temp.replace(char," ")
            # print("real_tam_temp",real_tam_temp)
            
            ranjak_search_vaux=real_tam_temp.split()[0]
            # print("rsv",ranjak_search_vaux)
            add_to_vaux=""
            # add_to_vaux=real_tam_temp.split()[1]
            # print(add_to_vaux)
            try:
                add_to_vaux=real_tam_temp.split()[1]
            except:
                pass
            root_of_ranjak_search_vaux=root_word_dict_reverse[ranjak_search_vaux.strip()]
            if root_of_ranjak_search_vaux in ranjak_list:
                real_tam_temp=root_word_dict[root_of_ranjak_search_vaux]
                real_tam_temp=suffix_dictionary[real_tam_temp.strip()]+" "+add_to_vaux
            else:  
                real_tam_temp=ranjak_search_vaux+" "+add_to_vaux
            # print("rtm",real_tam_temp)
            real_tam_search=wx_word_for_root_concept+" "+real_tam_temp
            #if "_" in real_tam_search:
            #    real_tam_search=real_tam_search.strip("_")
            # print("real tam search_2:",real_tam_search) #This is the real TAM that we work with,searching in the backend happens on this.
            key_tam=word_search_from_end(real_tam_search)
            # print("key_tam",key_tam)
            #The above function,returns the actual TAM matching from the TAM dictionary
            #if no match found in TAM dictionary,it returns none.
            #print("print key_tam is:",key_tam)
            #concept_list=list(map(lambda x:x.replace(concept_with_hyphen,key_tam),concept_list))
            init_part=concept_with_hyphen.split("-")[0]
            if key_tam is not None:
                final_concept=init_part+"-"+key_tam
            else:
                final_concept=init_part
        #print("final concept:",final_concept)
        #print("This is the final concept:",final_concept)
        concept_list=list(map(lambda x:x.replace(concept_with_hyphen,final_concept),concept_list))
        #print(concept_list)
        
    return concept_list
#----------------------------------------------------------------------
def pronouns_n_qnwords_to_replace(concept_list):
    concept_list_temp=concept_list
    category_1=["wuma","wumhArA","wumako","wuJe","wU","wuJako","Apa"]
    category_2=["mEM","hama","hamArA","hamako","hameM","muJe","muJako"]
    category_3=["Ji"]
    category_4=["vaha","yaha"]
    category_5=["kyA","kOna","kaba","kahAz","kEse","kisase","kEsA","kyoM","kisane","kisako","kisaki","kiwanA","kiwanI","kisaliye"]
    for index in range(len(concept_list_temp)):
        word=concept_list_temp[index]
        if "+" in word:
            continue
        else:
            if word in category_1:
                concept_list_temp[index]="addressee"
            elif word in category_2:
                concept_list_temp[index]="speaker"
            elif word in category_3:
                concept_list_temp[index]="respect"
            elif word in category_4:
                concept_list_temp[index]="wyax"
            elif word in category_5:
                concept_list_temp[index]="kim"
            else:
                continue
    return concept_list_temp
#----------------------------------------------------------------------------------------------------------
def for_handling_prpc(word,word_index):
    #print("wi",word_index)
    line= info_list_final[word_index] #updated simply vaux to vaux root
    #print("line",line)
    pos_tag=line[1]
    if pos_tag=="PRP":
        word_index=line[0]
        temp=wx_words_dictionary[word_index]
        #print("temp",temp)
        already_visited[temp]=1
        final_word=root_word_dict_reverse[word]+"+"+root_word_dict_reverse[temp]
    else:
        final_word=word
    return final_word

    

def get_row2():
    #pos_tag_dictionary={}#where key is wx_word and value is pos_tag
    
    #already_visited={}
    
    
    counter=0
    for word in wx_output_list:
        
        word_index=wx_words_dictionary_new[word] #word index of the word in wx_list
        for line in info_list_final:
            if word_index in line:
                pos_tag=line[1]
                class_index=int(line[2])
                word_info=line[3]
                #print("word_info:",word_info)
                #dependency=
        #main condition check begins here:
        
        if pos_tag=="PSP"  or pos_tag=="SYM" or pos_tag=="CC" or pos_tag=="RP":
            continue
        elif pos_tag=="VM" and word_info=="main": #Do not add suffix for these words because we have to do TAM search on them and it creates a problem later.
            #print("this is the word:",word)
            root_word=get_root_word(word)
            vector_8th=get_8th_vector(word)
            if word in VM_already_visited:
                
                root_word=VM_already_visited[word]
                concept_list.remove(root_word)

                final_word=root_word+"-"
            else:
                final_word=root_word+"_1"+"-"
            
            
            
            for line in info_list_final[word_index:-1]: #updated simply vaux to vaux root
                pos_tag=line[1]
                if pos_tag=="VAUX":
                    word_index=line[0]
                    temp=wx_words_dictionary[word_index]
                    #temp_root=root_word_dict_reverse[temp]
                    final_word=final_word+"_"+temp
                    #print(final_word)
                    already_visited[temp]=1
                else:
                    break
            
            VM_already_visited[word]=final_word #adding to the dictionary
            #sprint("this is final word:",final_word)
            concept_list.append(final_word)
        elif pos_tag=="VAUX" :
            if word in already_visited:
                if already_visited[word]==1:
                    continue
            else:
                root_word=get_root_word(word)
                concept_list.append(root_word+"_1")
        elif pos_tag=="NNC" or word_info=="pof":

            final_word=for_handling_nnc_tag_or_pof(word,class_index)
            concept_list.append(final_word)
        elif pos_tag=="PRPC":
            #print("word in use",word)
            final_word=for_handling_prpc(word,word_index)
            concept_list.append(final_word)
        else:
            if word in already_visited:
                continue
            root_word=get_root_word(word)
            if pos_tag=="PRP" or pos_tag=="DEM" or pos_tag=="NNP" :
                concept_list.append(root_word)
            else:
                concept_list.append(root_word+"_1")
        counter+=1
    
    #print(concept_list)
    concept_list_final=search_tam_row2(concept_list)
    #print("concept list final:",concept_list_final)
    return concept_list_final

#--------------------------------------------------------------------
  

#Row 3 of USR:Index for concepts
def get_row3(concept_list):
    index_for_concepts=[]
    for ind in range(len(concept_list)):
        index_for_concepts.append(ind+1)
    return index_for_concepts
#----------------------------------------------------------------------
#Row 4 of USR:Semantic category of Nouns
def get_row4(row_2):
     # print(row_2)
    sem_category_list=[]
    #for key in NER_dict:
     #   print(key)
    
    gen_info = prune_output_list
    sem_category_list=[]
    #for key in NER_dict:
     #   print(key)
    #print(gen_info)
    for item in gen_info:
        prune_list_for_con = item.split(',')
        gen_from_prune = prune_list_for_con[3]
        #print(gen_from_prune)
        if gen_from_prune == "m":
            gen_from_prune = "male"
        elif gen_from_prune == "f":
            gen_from_prune = "female"
        else: 
            gen_from_prune = ""
        # print(gen_from_prune)
        # sem_category_list.append(gen_from_prune)
    if len(NER_dict)==0:
        for concept in row_2:
            #print(concept)
            sem_category_list.append("")
    else:
        for concept in row_2:
            flag=0
            for word in NER_dict:
                if word in concept:
                    flag=1
                    if NER_dict[word] =="B-PER":
                        ner_val="per"
                    elif NER_dict[word]=="B-LOC":
                        ner_val="loc"
                    elif NER_dict[word]=="B-ORG" or NER_dict[word]=="I-ORG":
                        ner_val="org"
                    sem_category_list.append(ner_val)
            if flag==0:
                sem_category_list.append("")
    #print(sem_category_list)
    #print("sem_list:",sem_category_list)

        
    return sem_category_list
#---------------------------------------------------------------------   
#Row 5 :Gender,Number,Person Information only for nouns (NN tag in parser)
#updated 20th august 2022:GNP also for Pronouns..PRP tag in parser
def get_row5(row_2):
    gnp_list_temp=[]
    row_5_temp=[]
    for concept in row_2:
        concept=concept.strip()
        #print(concept)
        if "+" in concept or "-" in concept or "_" in concept:
            #print("this:",concept)
            row_5_temp.append(",")
        else:
            #concept=concept.split("_")[0]
            #original_word=root_word_dict[concept]
            row_5_temp.append(concept)
    #row_5_temporary is a list containing words and commas which we need to check
    
    #print("bef:",row_5_temp)
    for word in row_5_temp:
        if word==",":
            gnp_list_temp.append("")
        else:
            # gender="-"
            number="-"
            # person="-"
            for line in prune_output_list:
                #print(line)
                if word == line.split(",")[2]:
                    #print("line",line)
                    #gender=line.split(",")[3]
                    number=line.split(",")[4]
                    #person=line.split(",")[5]
                    #print("gender:",gender)
                    # if gender=="unk":
                    # if person=="unk":
                    #     person="-"
                     #     gender="-"
                    if number=="s":
                        number="sg"
                    if number=="p":
                        number="pl"
                    if number=="unk":
                        number=""
            # gnp_list_temp.append("["+""+gender+" "+number+" "+person+"]")
            gnp_list_temp.append(number)
                    
    #print("gnp_list_temp:",gnp_list_temp)               
    return gnp_list_temp
   
#---------------------------------------------------------------------
#Row 6:Dependencies


def get_row2_index(word):
    corr_index=0
    matched_concepts={}
    counter=1
    for concept_final in row_2:
        temp_list=concept_final.split("+")
        matched_concepts[counter]=temp_list
        counter+=1
    #print(matched_concepts)
    #print(row_2)
    for key,value in matched_concepts.items():
        for root_words in value:
            if "-" in root_words:
                root_words=root_words.split("-")[0]
            if "_1" in root_words:
                root_words=root_words.strip("_1")
            if word==root_words:
                corr_index=key
            #print("matched word is:",root_words)
            #print("Correct index is:",key)
            

    return corr_index

def get_row6(row_2):
    
    #print("This is row_2:",row_2)
    #wx_word_inx=0
    row_6=[]
    row2_iter=[]#a list which is cleaned part of row2 to be worked upon
    row2_wx_index_iter=[]#list which has correct indexes of words in row_2
    class_word_index_list=[]#list which contains indexes of all class_words
    class_word_index_dict={}
    class_word_list=[]#list of class words from their indexexes in wx_format
    root_word_from_wx=[]#list of root words from their wx words
    dependency_col7_list=[]#list of col7 values in parser output
    correct_index_list=[]#list of final indexexs of dependencies in row2
    pos_tag_list=[]#list of pos tags of words present.
    #print(row_2)
    for concepts in row_2:
        if "+" in concepts:
            concepts=concepts.split("+")[1]
        if "-" in concepts:
            concepts=concepts.split("-")[0]
        concepts=concepts.split("_")[0]
        row2_iter.append(concepts)
    #print("iterable:",row2_iter) #iterable after cleaning
    #print("root_word_dic",root_word_dict)
    for root_word in row2_iter:
        wx_word=root_word_dict.get(root_word)
        #print(wx_word)
        wx_word_inx=wx_words_dictionary_new[wx_word]
        #for key,value in temp_wx_words_dict.items():
         #   if value==wx_word:
          #      wx_word_inx=key
           #     value=0
        row2_wx_index_iter.append(wx_word_inx)
    
    #print("row2_wx_index:",row2_wx_index_iter) #indexes for same wx words
    
    for index_value in row2_wx_index_iter:
        par_value=parser_output_dict[index_value]
        class_word_index=int(par_value[6])
        pos_tag_value=par_value[3]
        dependency=par_value[7]
        class_word_index_list.append(class_word_index)
        dependency_col7_list.append(dependency)
        pos_tag_list.append(pos_tag_value)
    #print("class_word_indx_list:",class_word_index_list)
    #print("pos tag:",pos_tag_list)
    
    
    for index_6 in class_word_index_list:
        #do something about index_6==0 here
        if index_6==0:
            class_word_list.append(0)
        else:
            class_word_list.append(wx_words_dictionary[index_6])    
            
       # print(index_6)
    #print("This is class_word:",class_word_list)
    for word in class_word_list:
        if word==0:
            root_word_from_wx.append(0)
        else :
            key=root_word_dict_reverse[word]
            root_word_from_wx.append(key)
    #print("root of that class:",root_word_from_wx)
    #Now we have to find,where this word is in row_2 and get that index
    for word in root_word_from_wx:
        if word==0:
            correct_index_list.append(0)
            continue
        correct_index=get_row2_index(word)
        correct_index_list.append(correct_index)
    #print(correct_index_list)
    #print(dependency_col7_list)
    for val in range(len(dependency_col7_list)):
        if dependency_col7_list[val]=="main":
            row_6.insert(val,"0:main")
        else:
            #print(pos_tag_list[val])
            index_6a=str(correct_index_list[val])
            dependency_col7=dependency_col7_list[val]
            if  pos_tag_list[val]=="JJ":
                dependency_col7="mod"
            elif pos_tag_list[val]=="QC":
                dependency_col7="card"
            elif pos_tag_list[val]=="QO":
                dependency_col7="ord"
            elif dependency_col7=="lwg__neg":
                dependency_col7="neg"
            elif dependency_col7=="r6-k2":
                dependency_col7="k2"
            row_6.append(index_6a+":"+dependency_col7)
    #for word in row_6:
     #  if "r6-k2" in word:
      #  word.replace("r6-k2","r6")'''
    return row_6
#----------------------------------------------------------------------
#row 7
def get_row_unk(row_2):
    comma_list=[]
    for x in range(len(row_2)):
        comma_list.append("")
    return comma_list 
#--------------------------------------------------------------------
#row 8
def get_row8(row_2):
# Ranjak kriya infomation in 8th row
    ranjak_list = ["cala", "dAla", "cuka", "xe", "le", "bETa", "uTa", "jA", "padZa", "A"]
    complete_info = []

    for concept in row_2:
        if "-" in concept:
            
            for element in parser_output_list:
                pos = element[4]
                index = element[0]
                word_rel = element[7]
                word = element[1]
            
                if pos == "VM" and word_rel == "main":    
                    word = wx_words_dictionary[int(index)]
                    # print(word)
                    vm_next = int(index)+1
                    vm_next_word = wx_words_dictionary[vm_next]
                    # print(vm_next_word)
                    vm_next_ele = parser_output_list[vm_next-1]
                    # print(vm_next_ele)
                    vm_next_tag = vm_next_ele[4]
                    # print(vm_next_tag)

                    if vm_next_tag == "VAUX":
                        for tag in prune_output_list:
                            word_val = tag.split(',')
                            if vm_next_word == word_val[1]:
                                # print(word_val[2])
                                if word_val[2] in ranjak_list:
                                    # print(word_val[2]) # [shade:xe_1]
                                    complete_info.append("["+""+"shade"+":"+word_val[2]+"_1"+"]")     

                    else:
                        complete_info.append("") 
                                                                                       
        else:
            complete_info.append("")

# Discourse particle information in 8th row
    for word in row_2:
        for line in info_list_final:
            # print(line)
            if line[1] == "RP":
                rp_index = line[0]
                rp_rel = line[2]
                # print(rp_rel)            
                rp_word = wx_words_dictionary[rp_index]
                rp_root_word = root_word_dict_reverse[rp_word] # RP word in 8th row
                # print(rp_root_word)  
                rp_rel_word = wx_words_dictionary[int(rp_rel)]
                rp_rel_root_word = root_word_dict_reverse[rp_rel_word]

                row2_root = [word.replace("_1", "") for word in row_2]
                if rp_rel_root_word in row2_root:
                    rp_rel_word_index = row2_root.index(rp_rel_root_word)
                    # print(rp_rel_word_index)
                    for index in range(len(row_2)):
                        if rp_rel_word_index == index:
                            complete_info[index] = rp_root_word

    return complete_info

#-----------------------------------------------------------------------------
#Row 10:Sentence type
def get_row10():
    sentence_type=[]
    if "nahI" in wx_output_list or "nahIM" in wx_output_list:
        sentence_type.append('negative')
    else:
        if "?" in wx_output_list:
            sentence_type.append("interrogative")
        elif "|" in wx_output_list:
            sentence_type.append("affirmative")
        elif "." in wx_output_list:
            sentence_type.append("affirmative")
        elif "!" in wx_output_list:
            sentence_type.append("exclamatory")
    return sentence_type
#--------------------------------------------------------------------
def get_warning(row_2):
    for concept in row_2:
        if "_1" in concept:
            if "+" in concept and "-" in concept:
                search_word=concept.split("+")[1].split("-")[0]
                search_concept(search_word)
            elif "-" in concept:
                search_word=concept.split("-")[0]
                search_concept(search_word)
            else:
                search_concept(concept)

if __name__=="__main__":
    #row2 copy is a newlist,a copy of older one just to replace the pronouns.
    
        #row_2=get_row2()
        #print("Final output main:",row_2)
        #row_2_final=for_VM_no__1(row_2)
        #print("Final output main:",row_2_final)
        row_1=get_row1()
        row_2=get_row2()
        #print(row_2)
        row_2_temp=row_2.copy()
        row_2_chg=pronouns_n_qnwords_to_replace(row_2_temp)
        row_3=get_row3(row_2)
       # row_4=get_row4(row_2)
        row_5=get_row5(row_2)
        row_6=get_row6(row_2)
        row_7=get_row_unk(row_2)
        row_8=get_row8(row_2)
        row_9=get_row_unk(row_2)
        row_10=get_row10()
        #get_warning(row_2)
        print(row_1)
        print(",".join(row_2_temp))
        print(",".join(map(str,row_3)))
      #  print(",".join(row_4))
        print(",".join(map(str,row_5)))
        print(",".join(row_6))
        print(",".join(row_7))
        print(",".join(row_8))
        print(",".join(row_9))
        print(",".join(row_10))
        
                    
                

        
        

        







  






    





    


    
